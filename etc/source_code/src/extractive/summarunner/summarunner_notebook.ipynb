{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SummaRuNNer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import json\n",
    "import dill  # pip install dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from tqdm import tqdm  # pip install tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import random_split\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TestTubeLogger  # pip install test-tube\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    try:\n",
    "        from eunjeon import Mecab\n",
    "    except:\n",
    "        print(\"please install eunjeon module\")\n",
    "else:  # Linux or MacOS일 경우\n",
    "    from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Build Vocab\n",
    "\n",
    "- 학습 및 테스트에 사용할 vocabulary를 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(dataset, num_words=40000, stopwords=None):\n",
    "    # 0. tokenizer\n",
    "    tokenizer = Mecab()\n",
    "\n",
    "    # 1. tokenization\n",
    "    all_tokens = []\n",
    "    for data in tqdm(dataset):\n",
    "        sents = data[\"article_original\"]\n",
    "        for sent in sents:\n",
    "            tokens = tokenizer.morphs(sent)\n",
    "            if stopwords:\n",
    "                all_tokens.extend([token for token in tokens if token not in stopwords])\n",
    "            else:\n",
    "                all_tokens.extend(tokens)\n",
    "\n",
    "    # 2. build vocab\n",
    "    vocab = Counter(all_tokens)\n",
    "    vocab = vocab.most_common(num_words)\n",
    "\n",
    "    # 3. add pad & unk tokens\n",
    "    word_index = defaultdict()\n",
    "    word_index[\"<PAD>\"] = 0\n",
    "    word_index[\"<UNK>\"] = 1\n",
    "\n",
    "    for idx, (word, _) in enumerate(vocab, 2):\n",
    "        word_index[word] = idx\n",
    "\n",
    "    index_word = {idx: word for word, idx in word_index.items()}\n",
    "\n",
    "    return word_index, index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Feature Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    def __init__(self, word_index, tokenizer):\n",
    "        self.word_index = word_index\n",
    "        self.index_word = {idx: word for word, idx in word_index.items()}\n",
    "        assert len(self.word_index) == len(self.index_word)\n",
    "        self.PAD_IDX = 0\n",
    "        self.UNK_IDX = 1\n",
    "        self.PAD_TOKEN = \"<PAD>\"\n",
    "        self.UNK_TOKEN = \"<UNK>\"\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_index)\n",
    "\n",
    "    def index_to_word(self, idx):\n",
    "        return self.index_word[idx]\n",
    "\n",
    "    def word_to_index(self, w):\n",
    "        if w in self.word_index:\n",
    "            return self.word_index[w]\n",
    "        else:\n",
    "            return self.UNK_IDX\n",
    "\n",
    "    ###################\n",
    "    # Create Features #\n",
    "    ###################\n",
    "    def make_features(\n",
    "        self, docs, ext_idx_list, summaries_list, doc_trunc=50, sent_trunc=128,\n",
    "    ):\n",
    "\n",
    "        # trunc document\n",
    "        # 문서 내 doc_trunc 문장 개수까지 가져옴\n",
    "        sents_list, targets, doc_lens, ext_sums, abs_sums = [], [], [], [], []\n",
    "        for doc, ext_indices, abs_sum in zip(docs, ext_idx_list, summaries_list):\n",
    "            labels = []\n",
    "            for idx in range(len(doc)):\n",
    "                if idx in ext_indices:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "            max_sent_num = min(doc_trunc, len(doc))\n",
    "            sents = doc[:max_sent_num]\n",
    "            labels = labels[:max_sent_num]\n",
    "            ext_sum = [sent for sent, label in zip(sents, labels) if label == 1]\n",
    "\n",
    "            sents_list.extend(sents)\n",
    "            targets.extend(labels)\n",
    "            doc_lens.append(len(sents))\n",
    "            ext_sums.append(ext_sum)\n",
    "            abs_sums.append(abs_sum)\n",
    "\n",
    "        # trunc or pad sent\n",
    "        # 문장 내 sent_trunc 단어 개수까지 가져옴\n",
    "        max_sent_len = 0\n",
    "        batch_sents = []\n",
    "        for sent in sents_list:\n",
    "            words = self.tokenizer.morphs(sent)\n",
    "            if len(words) > sent_trunc:\n",
    "                words = words[:sent_trunc]\n",
    "            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
    "            batch_sents.append(words)\n",
    "\n",
    "        features = []\n",
    "        for sent in batch_sents:\n",
    "            feature = [self.PAD_IDX for _ in range(max_sent_len - len(sent))] + [\n",
    "                self.word_to_index(w) for w in sent\n",
    "            ]\n",
    "            features.append(feature)\n",
    "\n",
    "        return features, targets, doc_lens, ext_sums, abs_sums, docs\n",
    "\n",
    "    def make_predict_features(\n",
    "        self, docs, doc_trunc=50, sent_trunc=128,\n",
    "    ):\n",
    "\n",
    "        sents_list, doc_lens = [], []\n",
    "        for doc in docs:\n",
    "            max_sent_num = min(doc_trunc, len(doc))\n",
    "            sents = doc[:max_sent_num]\n",
    "\n",
    "            sents_list.extend(sents)\n",
    "            doc_lens.append(len(sents))\n",
    "\n",
    "        max_sent_len = 0\n",
    "        batch_sents = []\n",
    "        for sent in sents_list:\n",
    "            words = self.tokenizer.morphs(sent)\n",
    "            if len(words) > sent_trunc:\n",
    "                words = words[:sent_trunc]\n",
    "            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
    "            batch_sents.append(words)\n",
    "\n",
    "        features = []\n",
    "        for sent in batch_sents:\n",
    "            feature = [self.PAD_IDX for _ in range(max_sent_len - len(sent))] + [\n",
    "                self.word_to_index(w) for w in sent\n",
    "            ]\n",
    "            features.append(feature)\n",
    "\n",
    "        return features, doc_lens, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Dataset & collate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumDataset(Dataset):\n",
    "    def __init__(self, path, phase=\"train\"):\n",
    "        self.phase = phase\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            jsonl = list(f)\n",
    "\n",
    "        self.data = []\n",
    "        for json_str in jsonl:\n",
    "            self.data.append(json.loads(json_str))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        doc_id = self.data[idx][\"id\"]\n",
    "        doc = self.data[idx][\"article_original\"]\n",
    "\n",
    "        if self.phase == \"train\":\n",
    "            ext_indices = self.data[idx][\"extractive\"]\n",
    "            summaries = self.data[idx][\"abstractive\"]\n",
    "            return doc, ext_indices, summaries, doc_id\n",
    "        else:\n",
    "            return doc, doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) collate function\n",
    "\n",
    "- Trainset DataLoader에 필요한 collate function을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, feature):\n",
    "    docs = [entry[0] for entry in batch]\n",
    "    labels_list = [entry[1] for entry in batch]\n",
    "    summaries_list = [entry[2] for entry in batch]\n",
    "    doc_ids = [entry[3] for entry in batch]\n",
    "\n",
    "    (\n",
    "        features,\n",
    "        targets,\n",
    "        doc_lens,\n",
    "        ext_sums,\n",
    "        abs_sums,\n",
    "        origin_docs,\n",
    "    ) = feature.make_features(docs, labels_list, summaries_list)\n",
    "\n",
    "    docs = []\n",
    "    labels = []\n",
    "    start = 0\n",
    "    pad_dim = len(features[0])\n",
    "    max_doc_len = max(doc_lens)\n",
    "    for doc_len in doc_lens:\n",
    "        stop = start + doc_len\n",
    "        doc = features[start:stop]\n",
    "        target = targets[start:stop]\n",
    "        start = stop\n",
    "\n",
    "        doc = torch.LongTensor(doc)\n",
    "        if len(doc) == max_doc_len:\n",
    "            docs.append(doc.unsqueeze(0))\n",
    "        else:\n",
    "            pad = torch.zeros(max_doc_len - doc_len, pad_dim, dtype=torch.long)\n",
    "            docs.append(torch.cat([doc, pad]).unsqueeze(0))\n",
    "\n",
    "        if len(target) == max_doc_len:\n",
    "            labels.append(torch.FloatTensor(target).unsqueeze(0))\n",
    "        else:\n",
    "            pad = torch.zeros(max_doc_len - doc_len)\n",
    "            target = torch.FloatTensor(target)\n",
    "            labels.append(torch.cat([target, pad]).unsqueeze(0))\n",
    "\n",
    "    docs = torch.cat(docs, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    targets = torch.FloatTensor(targets)\n",
    "    doc_lens = torch.LongTensor(doc_lens)\n",
    "    return docs, labels, doc_lens, max_doc_len, ext_sums, abs_sums, origin_docs, doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) global function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool1d(sequences, seq_lens):\n",
    "    out = []\n",
    "    for idx, tensor in enumerate(sequences):\n",
    "        tensor = tensor[: seq_lens[idx], :]\n",
    "        tensor = torch.t(tensor).unsqueeze(0)\n",
    "        out.append(F.avg_pool1d(tensor, tensor.size(2)))\n",
    "\n",
    "    out = torch.cat(out).squeeze(2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int = 100,\n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        dropout_p: float = 0.3,\n",
    "        pretrained_vectors: np.ndarray = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = (vocab_size,)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directs = 1\n",
    "        if bidirectional:\n",
    "            self.num_directs = 2\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        if pretrained_vectors is not None:\n",
    "            self.embed.weight.data.copy_(pretrained_vectors)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.embed.weight)\n",
    "\n",
    "        self.bilstm = nn.LSTM(\n",
    "            self.embed_dim,\n",
    "            self.hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            # dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def pad_doc(self, sents, doc_lens, max_doc_len):\n",
    "        pad_dim = sents.size(1)\n",
    "        sent_input = []\n",
    "        start = 0\n",
    "        for doc_len in doc_lens:\n",
    "            stop = start + doc_len\n",
    "            valid = sents[start:stop]\n",
    "            start = stop\n",
    "            if doc_len == max_doc_len:\n",
    "                sent_input.append(valid.unsqueeze(0))\n",
    "            else:\n",
    "                pad = Variable(torch.zeros(max_doc_len - doc_len, pad_dim)).type_as(\n",
    "                    sents\n",
    "                )\n",
    "                sent_input.append(torch.cat([valid, pad]).unsqueeze(0))\n",
    "\n",
    "        sent_input = torch.cat(sent_input, dim=0)  # .type_as(sents)\n",
    "        return sent_input\n",
    "\n",
    "    def forward(self, docs, doc_lens, max_doc_len):\n",
    "        sent_input = []\n",
    "        for idx, doc_len in enumerate(doc_lens):\n",
    "            doc = docs[idx][:doc_len]\n",
    "            sent_input.append(doc)\n",
    "        sent_input = torch.cat(sent_input, dim=0)\n",
    "        sent_lens = torch.sum(torch.sign(sent_input), dim=1).data\n",
    "\n",
    "        x = self.embed(sent_input)\n",
    "        output, _ = self.bilstm(x)\n",
    "        output = avg_pool1d(output, sent_lens)\n",
    "        output = self.pad_doc(output, doc_lens, max_doc_len)\n",
    "        output = output.type_as(docs)\n",
    "        output = output.type(torch.float)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Document Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 128,\n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        dropout_p: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directs = 1\n",
    "        if bidirectional:\n",
    "            self.num_directs = 2\n",
    "\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            # dropout=dropout,\n",
    "        )\n",
    "        # self.linear = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "    def forward(self, sents, doc_lens):\n",
    "        output, hidden = self.bilstm(sents)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Total Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int = 100,\n",
    "        hidden_dim: int = 128,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        dropout_p: float = 0.3,\n",
    "        pretrained_vectors: np.ndarray = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sent_encoder = SentenceEncoder(\n",
    "            vocab_size,\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout_p=dropout_p,\n",
    "            pretrained_vectors=pretrained_vectors,\n",
    "        )\n",
    "\n",
    "        self.doc_encoder = DocumentEncoder(\n",
    "            2 * hidden_dim,\n",
    "            hidden_dim,\n",
    "            num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout_p=dropout_p,\n",
    "        )\n",
    "\n",
    "    def forward(self, docs, doc_lens, max_doc_len):\n",
    "        encoded_sents = self.sent_encoder(docs, doc_lens, max_doc_len)\n",
    "        encoded_docs = self.doc_encoder(encoded_sents, doc_lens)\n",
    "        return encoded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SummaRuNNer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaRunner(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int = 100,\n",
    "        hidden_dim: int = 128,\n",
    "        pos_dim: int = 50,\n",
    "        pos_num: int = 100,\n",
    "        seg_num: int = 25,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        dropout_p: float = 0.3,\n",
    "        pretrained_vectors: np.ndarray = None,\n",
    "    ):\n",
    "        super(SummaRunner, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.abs_pos_embed = nn.Embedding(pos_num, pos_dim)  # absolute postion\n",
    "        self.rel_pos_embed = nn.Embedding(seg_num, pos_dim)  # relative position\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size, embed_dim, hidden_dim, num_layers, bidirectional, dropout_p\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(2 * hidden_dim, 2 * hidden_dim)\n",
    "\n",
    "        # Parameters of Classification Layer\n",
    "        # P(y_j = 1|h_j, s_j, d), Eq.6 in SummaRuNNer paper\n",
    "        self.content = nn.Linear(2 * hidden_dim, 1, bias=False)\n",
    "        self.salience = nn.Bilinear(2 * hidden_dim, 2 * hidden_dim, 1, bias=False)\n",
    "        self.novelty = nn.Bilinear(2 * hidden_dim, 2 * hidden_dim, 1, bias=False)\n",
    "        self.abs_pos = nn.Linear(pos_dim, 1, bias=False)\n",
    "        self.rel_pos = nn.Linear(pos_dim, 1, bias=False)\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def forward(self, docs, doc_lens, max_doc_len):\n",
    "        sent_out = self.encoder(docs, doc_lens, max_doc_len)\n",
    "        docs = avg_pool1d(sent_out, doc_lens)\n",
    "\n",
    "        probs = []\n",
    "        for index, doc_len in enumerate(doc_lens):\n",
    "            valid_hidden = sent_out[index, :doc_len, :]\n",
    "            doc = torch.tanh(self.fc(docs[index])).unsqueeze(0)\n",
    "            s = Variable(torch.zeros(1, 2 * self.hidden_dim)).type_as(docs)\n",
    "            for position, h in enumerate(valid_hidden):\n",
    "                h = h.view(1, -1)\n",
    "                # get position embeddings\n",
    "                abs_index = Variable(torch.LongTensor([[position]])).type_as(docs)\n",
    "                abs_index = abs_index.type(torch.long)\n",
    "                abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n",
    "\n",
    "                rel_index = int(round((position + 1) * 9.0 / doc_len.item()))\n",
    "                rel_index = Variable(torch.LongTensor([[rel_index]])).type_as(docs)\n",
    "                rel_index = rel_index.type(torch.long)\n",
    "                rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n",
    "\n",
    "                # classification layer\n",
    "                content = self.content(h)\n",
    "                salience = self.salience(h, doc)\n",
    "                novelty = -1 * self.novelty(h, torch.tanh(s))\n",
    "                abs_p = self.abs_pos(abs_features)\n",
    "                rel_p = self.rel_pos(rel_features)\n",
    "                # P(y_j = 1|h_j, s_j, d) Eq.6 in SummaRuNNer paper\n",
    "                prob = torch.sigmoid(\n",
    "                    content + salience + novelty + abs_p + rel_p + self.bias\n",
    "                )\n",
    "                s = s + torch.mm(prob, h)\n",
    "                probs.append(prob)\n",
    "\n",
    "        return torch.cat(probs).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Train the Model using Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Experiment Class\n",
    "\n",
    "- `pytorch_lightning`을 사용하여 학습을 진행할 `Experiment` 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(pl.LightningModule):\n",
    "    def __init__(self, model, lr):\n",
    "        super(Experiment, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self._loss = nn.BCELoss()\n",
    "\n",
    "    # ---------------------\n",
    "    # TRAINING\n",
    "    # ---------------------\n",
    "    def forward(self, docs, doc_lens, max_doc_len):\n",
    "        return self.model(docs, doc_lens, max_doc_len)\n",
    "\n",
    "    def loss_fn(self, preds, labels):\n",
    "        bce_loss = self._loss(preds, labels)\n",
    "        return bce_loss\n",
    "\n",
    "    def accuracy(self, preds, labels):\n",
    "        preds = torch.round(preds)\n",
    "        corrects = (preds == labels).float().sum()\n",
    "        acc = corrects / labels.numel()\n",
    "        return acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        docs, targets, doc_lens, max_doc_len, _, _, _, _ = batch\n",
    "\n",
    "        preds = self.forward(docs, doc_lens, max_doc_len)\n",
    "\n",
    "        labels = []\n",
    "        for idx, doc_len in enumerate(doc_lens):\n",
    "            label = targets[idx][:doc_len]\n",
    "            labels.append(label)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "\n",
    "        train_loss = self.loss_fn(preds, labels)\n",
    "        train_acc = self.accuracy(preds, labels)\n",
    "        log_dict = {\"train_acc\": train_acc.detach(), \"train_loss\": train_loss.detach()}\n",
    "\n",
    "        output = OrderedDict(\n",
    "            {\n",
    "                \"loss\": train_loss,\n",
    "                \"progress_bar\": {\"train_acc\": train_acc},\n",
    "                \"log\": log_dict,\n",
    "            }\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        docs, targets, doc_lens, max_doc_len, _, _, _, _ = batch\n",
    "\n",
    "        preds = self.forward(docs, doc_lens, max_doc_len)\n",
    "\n",
    "        labels = []\n",
    "        for idx, doc_len in enumerate(doc_lens):\n",
    "            label = targets[idx][:doc_len]\n",
    "            labels.append(label)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "\n",
    "        val_loss = self.loss_fn(preds, labels)\n",
    "        val_acc = self.accuracy(preds, labels)\n",
    "\n",
    "        tqdm_dict = {\"val_acc\": val_acc.detach(), \"val_loss\": val_loss.detach()}\n",
    "        output = OrderedDict(\n",
    "            {\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"log\": tqdm_dict,\n",
    "                \"progress_bar\": tqdm_dict,\n",
    "            }\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss_mean = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        val_acc_mean = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": val_loss_mean.detach(), \"val_acc\": val_acc_mean.detach()}\n",
    "\n",
    "    # ---------------------\n",
    "    # TRAINING SETUP\n",
    "    # ---------------------\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Train data Load\n",
    "\n",
    "- 학습 시킬 데이터셋을 불러 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./data/train.jsonl\"\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    jsonl = list(f)\n",
    "\n",
    "train_data = []\n",
    "for json_str in jsonl:\n",
    "    train_data.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Feature & Dataset & DataLoader 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "valid_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42803/42803 [00:54<00:00, 783.18it/s]\n"
     ]
    }
   ],
   "source": [
    "word_index, index_word = build_vocab(train_data)\n",
    "\n",
    "with open(\"./word_index.pkl\", \"wb\") as f:\n",
    "    dill.dump(word_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature class\n",
    "mecab = Mecab()\n",
    "feature = Feature(word_index, mecab)\n",
    "\n",
    "# Split Train, Valid Dataset\n",
    "dataset = SumDataset(train_path)\n",
    "val_len = int(len(dataset) * 0.2)\n",
    "train_len = len(dataset) - val_len\n",
    "trainset, validset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=partial(collate_fn, feature=feature),\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=validset,\n",
    "    batch_size=valid_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(collate_fn, feature=feature),\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SetUp Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SummaRunner(vocab_size=len(word_index))\n",
    "experiment = Experiment(model, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# TestTubeLogger\n",
    "# ----------------\n",
    "tt_logger = TestTubeLogger(\n",
    "    save_dir=\"./logs\", name=\"./summarunner\", debug=False, create_git_tag=False,\n",
    ")\n",
    "\n",
    "# ----------------\n",
    "# Checkpoint\n",
    "# ----------------\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"./checkpoints/summarunner{epoch:02d}_{val_loss:.3f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=True,\n",
    "    save_top_k=5,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# Trainer\n",
    "# ----------------\n",
    "\n",
    "trainer = Trainer(\n",
    "    gpus=2,\n",
    "    min_epochs=1,\n",
    "    logger=tt_logger,\n",
    "    num_sanity_val_steps=5,\n",
    "    callbacks=[early_stopping],\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val=2,\n",
    "    distributed_backend=\"dp\",\n",
    "    precision=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# Start Train\n",
    "# ----------------\n",
    "trainer.fit(experiment, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Test data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./data/test_public.jsonl\"\n",
    "\n",
    "# Dataset\n",
    "testset = SumDataset(test_path, phase=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Vocabulary\n",
    "\n",
    "- 학습에 사용한 Vocabulary를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = \"./word_index.pkl\"\n",
    "\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    word_index = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_collate_fn(batch, feature):\n",
    "    docs = [entry[0] for entry in batch]\n",
    "    doc_ids = [entry[1] for entry in batch]\n",
    "\n",
    "    features, doc_lens, origin_docs = feature.make_predict_features(docs)\n",
    "\n",
    "    docs = []\n",
    "    start = 0\n",
    "    pad_dim = len(features[0])\n",
    "    max_doc_len = max(doc_lens)\n",
    "    for doc_len in doc_lens:\n",
    "        stop = start + doc_len\n",
    "        doc = features[start:stop]\n",
    "        start = stop\n",
    "\n",
    "        doc = torch.LongTensor(doc)\n",
    "        if len(doc) == max_doc_len:\n",
    "            docs.append(doc.unsqueeze(0))\n",
    "        else:\n",
    "            pad = torch.zeros(max_doc_len - doc_len, pad_dim, dtype=torch.long)\n",
    "            docs.append(torch.cat([doc, pad]).unsqueeze(0))\n",
    "\n",
    "    docs = torch.cat(docs, dim=0)\n",
    "    doc_lens = torch.LongTensor(doc_lens)\n",
    "    return docs, doc_lens, max_doc_len, doc_ids, origin_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Feature & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "\n",
    "# Feature class\n",
    "feature = Feature(word_index, mecab)\n",
    "\n",
    "# DataLoader\n",
    "test_loader = DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(test_collate_fn, feature=feature),\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Pre-trained Weights Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"./checkpoints/summarunnerepoch=00_val_loss=0.448.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "checkpoint[\"state_dict\"] = OrderedDict(\n",
    "    [(key.replace(\"model.\", \"\"), val) for key, val in checkpoint[\"state_dict\"].items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SummaRunner(\n",
       "  (abs_pos_embed): Embedding(100, 50)\n",
       "  (rel_pos_embed): Embedding(25, 50)\n",
       "  (encoder): Encoder(\n",
       "    (sent_encoder): SentenceEncoder(\n",
       "      (embed): Embedding(40002, 100, padding_idx=0)\n",
       "      (bilstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (doc_encoder): DocumentEncoder(\n",
       "      (bilstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (content): Linear(in_features=256, out_features=1, bias=False)\n",
       "  (salience): Bilinear(in1_features=256, in2_features=256, out_features=1, bias=False)\n",
       "  (novelty): Bilinear(in1_features=256, in2_features=256, out_features=1, bias=False)\n",
       "  (abs_pos): Linear(in_features=50, out_features=1, bias=False)\n",
       "  (rel_pos): Linear(in_features=50, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------\n",
    "# SetUp Model\n",
    "# ----------------\n",
    "model = SummaRunner(vocab_size=len(word_index)).to(DEVICE)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:40,  3.88it/s]                         \n"
     ]
    }
   ],
   "source": [
    "num_topk = 3\n",
    "test_batch_size = 32\n",
    "\n",
    "model_summaries = []\n",
    "for batch in tqdm(test_loader, total=len(testset) // test_batch_size):\n",
    "    docs, doc_lens, max_doc_len, doc_ids, orgin_docs = batch\n",
    "    preds = model(docs.to(DEVICE), doc_lens, max_doc_len)\n",
    "\n",
    "    start = 0\n",
    "    for d_idx, doc_len in enumerate(doc_lens):\n",
    "        stop = start + doc_len\n",
    "        pred = preds[start:stop]\n",
    "\n",
    "        topk_indices = pred.topk(num_topk)[1].tolist()\n",
    "        topk_indices.sort()\n",
    "\n",
    "        doc = orgin_docs[d_idx]\n",
    "        doc_id = doc_ids[d_idx]\n",
    "        hyp = [doc[idx] for idx in topk_indices]\n",
    "\n",
    "        model_summaries.append((doc_id, \"\\n\".join(hyp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Submission csv 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311565946</td>\n",
       "      <td>▲ 당진시의회가 지난 10일 제55회 임시회를 열고 본격적인 의정활동을 시작했다.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343753227</td>\n",
       "      <td>‘어린이날(5월5일)’을 맞아 롯데백화점 광주점과 아울렛에서 아동 및 나들이 고객을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>336239968</td>\n",
       "      <td>‘孫 청문회’ 입장차는 여전 여야의 극한 대치로 올해 들어 폐업 상태였던 국회가 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343538710</td>\n",
       "      <td>태안 복군 30주년을 축하하고 도시 간 우호교류 협력과 민간분야 교류 활성화를 위해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>332820578</td>\n",
       "      <td>사진=뉴미디어팀대전 지역에 '빵 브랜드 전성시대'가 활짝 열렸다.\\n모종린 연세대 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            summary\n",
       "0  311565946  ▲ 당진시의회가 지난 10일 제55회 임시회를 열고 본격적인 의정활동을 시작했다.\\...\n",
       "1  343753227  ‘어린이날(5월5일)’을 맞아 롯데백화점 광주점과 아울렛에서 아동 및 나들이 고객을...\n",
       "2  336239968  ‘孫 청문회’ 입장차는 여전 여야의 극한 대치로 올해 들어 폐업 상태였던 국회가 4...\n",
       "3  343538710  태안 복군 30주년을 축하하고 도시 간 우호교류 협력과 민간분야 교류 활성화를 위해...\n",
       "4  332820578  사진=뉴미디어팀대전 지역에 '빵 브랜드 전성시대'가 활짝 열렸다.\\n모종린 연세대 ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(model_summaries, columns=[\"id\", \"summary\"])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
