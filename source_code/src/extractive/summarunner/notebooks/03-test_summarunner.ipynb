{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SummaRuNNer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TestTubeLogger  # pip install test-tube\n",
    "\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "from experiment import Experiment\n",
    "from model import SummaRunner\n",
    "from model import SumDataset, Feature\n",
    "from model import build_vocab, collate_fn\n",
    "from model.types_ import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# DataLoader\n",
    "# ----------------\n",
    "\n",
    "# data path\n",
    "test_path = config[\"exp_params\"][\"test_path\"]\n",
    "vocab_path = config[\"exp_params\"][\"vocab_path\"]\n",
    "\n",
    "# vocab\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    word_index = dill.load(f)\n",
    "\n",
    "# pretrained vectors\n",
    "\n",
    "# Feature class\n",
    "feature = Feature(word_index, Mecab())\n",
    "\n",
    "# Dataset\n",
    "testset = SumDataset(test_path)\n",
    "\n",
    "# DataLoader\n",
    "test_loader = DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=config[\"exp_params\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(collate_fn, feature=feature),\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    docs, labels, doc_lens, max_doc_len, ext_sums, abs_sums, orgin_docs = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'국회 국방위원회 소속 민홍청 의원이 통일시대를 대비하여 자연환경이 우수하고 나라의 슬픈 역사를 간직하고 있는 DMZ를 보전하고 DMZ의 평화적인 이용을 내용으로 하는 특별법을 발의하였다. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_sums[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"../checkpoints/summarunnerepoch=13_val_loss=0.446.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "checkpoint[\"state_dict\"] = OrderedDict(\n",
    "    [(key.replace(\"model.\", \"\"), val) for key, val in checkpoint[\"state_dict\"].items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SummaRunner(\n",
       "  (abs_pos_embed): Embedding(100, 50)\n",
       "  (rel_pos_embed): Embedding(25, 50)\n",
       "  (encoder): Encoder(\n",
       "    (sent_encoder): SentenceEncoder(\n",
       "      (embed): Embedding(40002, 100, padding_idx=0)\n",
       "      (bilstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (doc_encoder): DocumentEncoder(\n",
       "      (bilstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (content): Linear(in_features=256, out_features=1, bias=False)\n",
       "  (salience): Bilinear(in1_features=256, in2_features=256, out_features=1, bias=False)\n",
       "  (novelty): Bilinear(in1_features=256, in2_features=256, out_features=1, bias=False)\n",
       "  (abs_pos): Linear(in_features=50, out_features=1, bias=False)\n",
       "  (rel_pos): Linear(in_features=50, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------\n",
    "# SetUp Model\n",
    "# ----------------\n",
    "\n",
    "# vocab_size\n",
    "config[\"model_params\"][\"vocab_size\"] = len(word_index)\n",
    "\n",
    "model = SummaRunner(**config[\"model_params\"]).to(DEVICE)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 157/5000 [00:38<19:44,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "num_topk = 3\n",
    "file_id = 1\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    features, targets, doc_lens, ext_sums, abs_sums, docs = batch\n",
    "    preds = model(features.to(DEVICE), doc_lens)\n",
    "\n",
    "    start = 0\n",
    "    for doc_id, doc_len in enumerate(doc_lens):\n",
    "        stop = start + doc_len\n",
    "        pred = preds[start:stop]\n",
    "\n",
    "        topk_indices = pred.topk(num_topk)[1].tolist()\n",
    "        topk_indices.sort()\n",
    "\n",
    "        doc = docs[doc_id]\n",
    "        hyp = [doc[idx] for idx in topk_indices]\n",
    "        ext_ref = ext_sums[doc_id]\n",
    "        abs_ref = abs_sums[doc_id]\n",
    "\n",
    "        with open(f\"../outputs/ext_ref/{file_id}.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "            f.write(\"\\n\".join(ext_ref))\n",
    "        with open(f\"../outputs/abs_ref/{file_id}.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "            f.write(\"\\n\".join(abs_ref))\n",
    "        with open(f\"../outputs/hyp/{file_id}.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "            f.write(\"\\n\".join(hyp))\n",
    "\n",
    "        start = stop\n",
    "        file_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
