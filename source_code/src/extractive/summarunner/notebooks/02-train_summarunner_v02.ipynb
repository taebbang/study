{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SummaRuNNer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from model import SummaRunner\n",
    "from model import SumDataset, Feature\n",
    "from model import build_vocab\n",
    "from model.types_ import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = \"../utils/word_index_v02.pkl\"\n",
    "train_path = \"../../../../datasets/kor_data/total_data/train_50965.jsonl\"\n",
    "dev_path = \"../../../../datasets/kor_data/total_data/dev_50965.jsonl\"\n",
    "test_path = \"../../../../datasets/kor_data/total_data/test_50965.jsonl\"\n",
    "model = SummaRunner(\n",
    "    vocab_path,\n",
    "    train_path,\n",
    "    dev_path,\n",
    "    test_path,\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    test_batch_size=32,\n",
    "    lr=0.01,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = model.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    features, targets, doc_lens, ext_sums, abs_sums, docs = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(features.cuda(), doc_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3818, 0.8009, 0.7191, 0.3001, 0.3876, 0.4302, 0.4295, 0.4774, 0.7490,\n",
       "        0.4967, 0.3320, 0.6477, 0.3817, 0.5290, 0.7185, 0.8452, 0.0977, 0.1142,\n",
       "        0.5736, 0.4611, 0.5698, 0.5850, 0.5781, 0.7479, 0.7561, 0.5955, 0.4876,\n",
       "        0.2911, 0.5026, 0.6886, 0.2398, 0.5391, 0.7267, 0.1980, 0.3348, 0.3657,\n",
       "        0.5291, 0.4164, 0.8449, 0.5801, 0.6228, 0.1881, 0.1280, 0.7041, 0.7172,\n",
       "        0.5632, 0.6093, 0.5800, 0.5562, 0.7229, 0.5731, 0.6613, 0.6682, 0.3064,\n",
       "        0.5690, 0.8248, 0.5957, 0.3818, 0.8009, 0.7191, 0.3001, 0.3876, 0.2962,\n",
       "        0.5896, 0.5185, 0.7490, 0.4964, 0.4598, 0.3817, 0.2396, 0.5388, 0.5816,\n",
       "        0.4016, 0.2269, 0.4730, 0.3818, 0.8010, 0.7191, 0.3001, 0.3876, 0.2961,\n",
       "        0.5895, 0.5186, 0.7489, 0.4962, 0.4601, 0.3818, 0.8010, 0.7192, 0.3002,\n",
       "        0.3876, 0.2962, 0.5897, 0.5186, 0.7490, 0.4965, 0.4601, 0.3817, 0.5292,\n",
       "        0.7187, 0.2997, 0.0974, 0.4290, 0.4284, 0.4764, 0.7164, 0.7603, 0.3341,\n",
       "        0.5187, 0.6185, 0.3818, 0.8010, 0.1670, 0.7141, 0.2607, 0.4451, 0.6281,\n",
       "        0.2502, 0.6123, 0.3817, 0.8009, 0.1669, 0.7139, 0.3869, 0.2954, 0.5892,\n",
       "        0.5176, 0.4805, 0.6265, 0.6885, 0.6486, 0.3952, 0.7582, 0.2977, 0.3818,\n",
       "        0.8009, 0.7191, 0.3001, 0.3876, 0.2962, 0.5896, 0.5185, 0.7489, 0.4965,\n",
       "        0.4600, 0.3818, 0.5292, 0.7187, 0.8453, 0.0978, 0.1142, 0.5738, 0.4615,\n",
       "        0.5702, 0.7296, 0.5785, 0.7780, 0.7562, 0.3140, 0.4851, 0.4101, 0.3656,\n",
       "        0.5293, 0.4166, 0.8449, 0.5801, 0.1145, 0.1874, 0.4610, 0.7037, 0.5854,\n",
       "        0.4177, 0.7480, 0.7246, 0.5960, 0.7542, 0.2943, 0.3763, 0.5156, 0.4244,\n",
       "        0.3818, 0.8010, 0.1670, 0.7141, 0.3874, 0.2960, 0.5893, 0.5180, 0.4808,\n",
       "        0.6267, 0.3818, 0.8009, 0.1670, 0.7141, 0.3874, 0.2959, 0.5893, 0.5178,\n",
       "        0.4806, 0.6267, 0.3657, 0.5291, 0.4164, 0.8449, 0.5799, 0.6226, 0.1880,\n",
       "        0.1279, 0.7040, 0.7172, 0.5633, 0.6091, 0.5799, 0.5561, 0.7228, 0.5731,\n",
       "        0.6616, 0.6694, 0.3081, 0.5699, 0.8254, 0.5964, 0.3816, 0.8008, 0.1669,\n",
       "        0.7142, 0.3873, 0.2958, 0.5889, 0.5176, 0.4805, 0.6265, 0.3818, 0.8010,\n",
       "        0.1670, 0.7141, 0.2606, 0.4451, 0.6282, 0.2503, 0.6123, 0.3655, 0.5292,\n",
       "        0.4165, 0.8449, 0.5800, 0.1144, 0.1873, 0.4608, 0.7036, 0.7167, 0.4178,\n",
       "        0.6084, 0.7246, 0.5556, 0.7540, 0.5720, 0.3771, 0.3846, 0.4290, 0.6879,\n",
       "        0.3819, 0.8010, 0.7192, 0.3002, 0.3877, 0.4303, 0.4297, 0.4777, 0.7495,\n",
       "        0.4979, 0.3332, 0.6477, 0.3818, 0.8010, 0.1670, 0.7141, 0.2606, 0.4451,\n",
       "        0.6282, 0.2503, 0.6123, 0.6885, 0.2398, 0.5391, 0.7268, 0.1980, 0.3348,\n",
       "        0.6885, 0.2398, 0.5391, 0.7267, 0.1980, 0.3348, 0.3818, 0.8010, 0.7192,\n",
       "        0.3001, 0.3876, 0.2962, 0.5896, 0.5186, 0.7490, 0.4965, 0.4600, 0.3818,\n",
       "        0.8010, 0.1670, 0.7141, 0.4025, 0.4861, 0.3447, 0.3633, 0.3817, 0.8008,\n",
       "        0.7190, 0.3002, 0.3876, 0.2961, 0.5896, 0.5185, 0.7489, 0.4963, 0.4599,\n",
       "        0.3657, 0.5292, 0.4165, 0.8450, 0.5802, 0.1145, 0.1874, 0.4611, 0.7038,\n",
       "        0.7169, 0.4180, 0.6086, 0.7247, 0.5558, 0.7544, 0.5727, 0.3781, 0.3849,\n",
       "        0.4294, 0.6882, 0.3818, 0.5292, 0.7187, 0.2997, 0.0974, 0.4289, 0.5733,\n",
       "        0.3228, 0.7164, 0.7291, 0.6171, 0.5206, 0.4883, 0.4345, 0.3819, 0.8010,\n",
       "        0.1670, 0.7140, 0.4024, 0.4860, 0.3446, 0.3632, 0.3818, 0.5292, 0.7187,\n",
       "        0.2997, 0.0974, 0.4288, 0.5733, 0.3229, 0.7165, 0.7291, 0.6171, 0.5206,\n",
       "        0.4881, 0.4344], device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
